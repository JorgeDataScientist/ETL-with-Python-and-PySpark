# ProyectoS de Análisis de Datos con PySpark

Estos proyectos utiliza **PySpark** para realizar un análisis de datos en un diferetes conjuntos de datos. Se realizaron diversas operaciones para transformar y visualizar los datos. Además, se creó un entorno virtual con `virtualenv` para gestionar las dependencias del proyecto.

## Tabla de Contenidos
1. [Requisitos](#requisitos)
2. [Creación del Entorno Virtual](#creación-del-entorno-virtual)
3. [Proceso de Análisis y Escalado](#proceso-de-análisis-y-escalado)
4. [Visualización de Datos](#visualización-de-datos)
5. [Conclusión](#conclusión)

## Requisitos

Antes de comenzar, asegúrate de tener instalados los siguientes programas:
- **Python 3.x**
- **Java** (para utilizar PySpark)
- **Spark** (PySpark está basado en Apache Spark)
- **Virtualenv** (para la gestión del entorno virtual)

### Instalar Dependencias
En el entorno virtual, se instalaron las siguientes dependencias:

```bash
pip install pyspark pandas matplotlib seaborn
